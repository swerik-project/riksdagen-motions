<?xml version="1.0" encoding="utf-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="mot-201718-UU-02655">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>Förbjud autonoma dödliga vapensystem och reglera utvecklingen av artificiell intelligens</title>
        <author corresp="i-42mC5GTVNHcPV5LNMmxmrj">av Carl Schlyter (MP)</author>
      </titleStmt>
      <publicationStmt>
        <authority>SWERIK PROJECT</authority>
      </publicationStmt>
      <sourceDesc>
        <bibl>
          <title>Motion 2017/18:2655 av Carl Schlyter (MP)</title>
          <idno type="rdwebb">H5022655</idno>
          <rs type="number">2655</rs>
          <orgName type="comitteeAbbreviation">UU</orgName>
          <ref type="dokument_url_text">http://data.riksdagen.se/dokument/H5022655/text</ref>
          <ref type="dokument_url_html">http://data.riksdagen.se/dokument/H5022655</ref>
          <ref type="dokumentstatus_url_xml">http://data.riksdagen.se/dokumentstatus/H5022655</ref>
          <ref type="docx">http://data.riksdagen.se/fil/A5BD55EB-2C43-49A4-9A6F-4AC72A4762EC</ref>
          <ref type="pdf">http://data.riksdagen.se/fil/492A05A2-3B50-4265-8511-18A021502443</ref>
        </bibl>
      </sourceDesc>
    </fileDesc>
    <profileDesc>
      <particDesc>
        <listPerson>
          <person gender="man">
            <idno>i-42mC5GTVNHcPV5LNMmxmrj</idno>
            <name>Carl Schlyter</name>
            <state type="partyAffiliation" ref="Q213451">
              <desc>MP</desc>
            </state>
          </person>
        </listPerson>
      </particDesc>
      <correspDesc>
        <correspAction type="status" subtype="closed"/>
        <correspAction xml:id="i-FoXw9M6Jex3ayh6aPmFhiW" type="signed"/>
        <correspContext corresp="i-FoXw9M6Jex3ayh6aPmFhiW">
          <note type="signatory" corresp="i-42mC5GTVNHcPV5LNMmxmrj"/>
        </correspContext>
        <correspAction xml:id="i-G6XKSH2xP5SqpWQwqxbhXs" type="submitted">
          <date when="2017-10-04"/>
          <time when="14:43:57"/>
        </correspAction>
        <correspAction xml:id="i-WF4okmMZyR1zzEZS1Y9aG6" type="reviewed">
          <date when="2017-10-04"/>
          <time when="15:26:34"/>
        </correspAction>
        <correspAction xml:id="i-Be9UW5A9o4YEt7UndwaRx9" type="referred">
          <date when="2017-10-13"/>
        </correspAction>
        <correspAction xml:id="i-EuGrqatE6sEdgnSPqzEEpA" type="assigned">
          <date when="2018-10-31"/>
          <time when="13:17:26"/>
        </correspAction>
        <correspContext corresp="i-EuGrqatE6sEdgnSPqzEEpA">
          <ref type="assignedTo">Utrikesutskottet</ref>
        </correspContext>
        <correspAction xml:id="i-HDu9Jd53ovdQsYQwCjaXBQ" type="behandlas_i"/>
        <correspContext corresp="i-HDu9Jd53ovdQsYQwCjaXBQ">
          <ref type="uppgift">2017/18:UU8</ref>
          <ref type="ref_dok_id">H501UU8</ref>
          <ref type="ref_dok_typ">bet</ref>
          <ref type="ref_dok_rm">2017/18</ref>
          <ref type="ref_dok_bet">UU8</ref>
          <ref type="ref_dok_titel">Sveriges samlade politik för internationell civil och militär krishantering</ref>
          <ref type="ref_dok_subtyp">bet</ref>
          <ref type="ref_dok_dokumentnamn">Betänkande</ref>
        </correspContext>
        <correspAction xml:id="i-9vFKvt1gGQFKXQVWSUnvG8" type="behandlas_i"/>
        <correspContext corresp="i-9vFKvt1gGQFKXQVWSUnvG8">
          <ref type="uppgift">2017/18:UU11</ref>
          <ref type="ref_dok_id">H501UU11</ref>
          <ref type="ref_dok_typ">bet</ref>
          <ref type="ref_dok_rm">2017/18</ref>
          <ref type="ref_dok_bet">UU11</ref>
          <ref type="ref_dok_titel">Säkerhetspolitik</ref>
          <ref type="ref_dok_subtyp">bet</ref>
          <ref type="ref_dok_dokumentnamn">Betänkande</ref>
        </correspContext>
        <correspAction xml:id="i-4mfX8tW4mfSfyWve3HS3BV" type="behandlas_i"/>
        <correspContext corresp="i-4mfX8tW4mfSfyWve3HS3BV">
          <ref type="uppgift">2017/18:TU9</ref>
          <ref type="ref_dok_id">H501TU9</ref>
          <ref type="ref_dok_typ">bet</ref>
          <ref type="ref_dok_rm">2017/18</ref>
          <ref type="ref_dok_bet">TU9</ref>
          <ref type="ref_dok_titel">It-politik</ref>
          <ref type="ref_dok_subtyp">bet</ref>
          <ref type="ref_dok_dokumentnamn">Betänkande</ref>
        </correspContext>
      </correspDesc>
      <textClass>
        <catRef scheme="#docType" target="#mot"/>
        <catRef scheme="#motionType" target="#enskild"/>
        <catRef scheme="#motionType" target="#fristående"/>
      </textClass>
    </profileDesc>
  </teiHeader>
  <text>
    <body>
      <div type="motHeader">
        <div type="motTitle">
          Motion till riksdagen 2017/18:2655 av Carl Schlyter (MP) Förbjud
          autonoma dödliga vapensystem och reglera utvecklingen av artificiell
          intelligens
        </div>
      </div>
      <div type="motBody">
        <div type="motProposal" subtype="förslag">
          <head xml:id="i-VhFwR7pPFDSnZQEoetKoWt">
            Förslag till riksdagsbeslut
          </head>
          <list style="ol">
            <item xml:id="i-NG8yDGdxMNjNGkbsK3HnND">
              Riksdagen ställer sig bakom det som anförs i motionen om att
              Sverige ska utarbeta ett nationellt förbud mot autonoma dödliga
              vapensystem samt arbeta för internationella förbud där så är möjligt
              och tillkännager detta för regeringen.
            </item>
            <item xml:id="i-Q1KyX4KFYDneyTLTTfq7F9">
              Riksdagen ställer sig bakom det som anförs i motionen om att
              utvärdera risker med artificiell intelligens för att säkerställa
              mänsklig kontroll och tillkännager detta för regeringen.
            </item>
          </list>
        </div>
        <div type="motContent">
          <head xml:id="i-JFTA6qfEXGY9eUpPkdSjUU" type="h1">
            Motivering
          </head>
          <p xml:id="i-49iK7D1nMm8uV6P9JJp8p2">
            Vi har redan internationella förbud mot personminor eftersom
            de dödar icke-diskriminerande oavsett om det är ett barn eller
            en fientlig soldat som trampar på den. Den ligger där beredd och
            dödar den som trampar på den.
          </p>
          <p xml:id="i-3fKnAPQWuVFEn9L2v4GMo1">
            Länge har också försvarsvapen med automatiska funktioner funnits
            som närskydds­system till fartyg av typen Phalanx eller CIWS,
            de är designade för att förstöra t ex inkommande missiler där
            det inte finns tid att invänta mänsklig målprioritering. Dessa
            system är dock ombord på fartyg där människor kan påverka situationen
            med kort varsel.
          </p>
          <p xml:id="i-QrzZj8hgdC4y5crJvyhv54">
            Nu har nya vapen som kan döda människor utan att det finns möjlighet
            för mänskliga beslut utvecklats eller är på väg att utvecklas.
            Till skillnad från personminor har dessa nya vapen förmågan att
            också offensivt söka upp offer från luften, havet eller marken.
          </p>
          <p xml:id="i-3EeNMWdPmnrLJzavDmRjq6">
            De är också utrustade med mer avancerade sensorer och har även
            primitiv artificiell intelligens som stöd för beslut att sätta
            in en vapeninsats. Kännetecknet för ett autonomt dödligt vapen
            är att det inte är en människa som beslutar om en insats.
          </p>
          <p xml:id="i-DD8u5b4fVfRtKGPAcA9zR8">
            Forskare på en AI-konferens skrev 2015 på ett upprop mot dessa
            vapen.
            <ref target="i-U4Skiewj7Ckp1NWULHRrZm">
              [1]
            </ref>
            Ledare för 116 företag som sysslar med artificiell intelligens
            från 26 länder skrev i augusti på ett upprop där de vill att FN
            förbjuder autonoma vapensystem.
            <ref target="i-WcqY8HR135CMva4agEqUvH">
              [2]
            </ref>
            I december 2016 inledde FN sitt arbete med frågan inom ramen
            för UN Review Conference of the Convention on Conventional Weapons.
            13–17 november hålls den andra uppföljningskonferensen i ämnet
            i Genѐve.
          </p>
          <p xml:id="i-DwWFN99cphiV5h8mGKGdjz">
            Följande 19 länder har redan skrivit på att de eftersträvar ett
            förbud:
          </p>
          <list style="ol">
            <item xml:id="i-JhRX6FTnatAWBCP7zJfgUu">
              Algeriet
            </item>
            <item xml:id="i-PKrv9hBJvPQ7pLNKChKBdL">
              Argentina
            </item>
            <item xml:id="i-LYTWVA2jDcaqR5DhYZQ5do">
              Bolivia
            </item>
            <item xml:id="i-TdaWRDyDrs1jxykkR1ExoN">
              Chile
            </item>
            <item xml:id="i-VCPyaEqs4TemXtKyq68Auk">
              Costa Rica
            </item>
            <item xml:id="i-2rBvg5pzDVJrVMYxs6zb81">
              Cuba
            </item>
            <item xml:id="i-KjVjuwjR91JveBdwACZDk4">
              Ecuador
            </item>
            <item xml:id="i-FwwE1TR4UQaBvGauSd49UD">
              Egypten
            </item>
            <item xml:id="i-4PzEmqdia2ZZuc5qCA6H7X">
              Ghana
            </item>
            <item xml:id="i-TTMNhJStFPZ3Bhm2xV8cyQ">
              Guatemala
            </item>
            <item xml:id="i-M4HbZ2yxoGFG6mjL8kN4wv">
              Vatikanen
            </item>
            <item xml:id="i-TX9i5BvM2JMZde4RgccM3w">
              Mexiko
            </item>
            <item xml:id="i-S4EE57xDVqNBbeE7VHgx4m">
              Nicaragua
            </item>
            <item xml:id="i-R9b33zgyXYeL1Rn2HhWxSt">
              Pakistan
            </item>
            <item xml:id="i-8T4JtzrHbcvsw5jyGCwbtQ">
              Panama
            </item>
            <item xml:id="i-HUb35vtcjBS1rw3ym5d5ND">
              Peru
            </item>
            <item xml:id="i-JBeoxAY51NRJ2FFFckHop1">
              Palestina
            </item>
            <item xml:id="i-oSWqasp1mTpYTRKoJ3BT3">
              Venezuela
            </item>
            <item xml:id="i-BZWPVqWu1XfAwsmVBPpkpB">
              Zimbabwe
            </item>
          </list>
          <p xml:id="i-EiPR1mAykHacjRztGecuG4">
            Sverige borde ta initiativ inom ramen för nordiska rådet, EU,
            OSSE och FN för att stödja kampen för att undvika dessa vapen.
            Farhågorna är att de inte kommer att kunna skilja på stridande
            och icke-stridande samt att tröskeln för att starta ett krig sänks
            när risken att offra egna soldater blir mindre. Dessutom finns
            det en stor risk att de hamnar i orätta händer. När tekniken blir
            billig, lättillgänglig och miniatyriserad kommer det finnas en
            uppenbar risk att civila kommer drabbas och tröskeln till våld
            sänks. Risk finns också att kriminella eller terrorister skulle
            kunna få tag på dem. Kina har som första land från de permanenta
            staterna i säkerhetsrådet vid den senaste konferensen uttryckt
            tveksamhet kring att dessa vapen någonsin kan fungera utan att
            strida mot folkrätten.
          </p>
          <p xml:id="i-KvyuVTYQJiLaZGXtMAHGfg">
            Eftersom dessa vapen ännu inte finns tillgängliga i kommersiell
            skala finns det en möjlighet att förbjuda dem idag. Sverige bör
            därför snarast agera.
          </p>
          <head xml:id="i-PojG1Bki6qehRirobUi5Km" type="h2">
            Bakgrund artificiell intelligens
          </head>
          <p xml:id="i-P35BCBR2fXwGTqF8ZFzLW7">
            Artificiell intelligens har stora möjligheter att hjälpa oss
            att fatta bättre beslut och öka det tekniska kunnandet. Men den
            har också möjligheten att övervaka oss och styra oss mot andra
            mål än de vi själva önskar. Redan idag finns enorma datamängder
            som kan analyseras med hjälp av AI. Dessa kan sedan användas för
            att förutsäga och även kontrollera mänskligt beteende. I ett senare
            skede kan även detta då ske automatiserat med hjälp av AI. Då
            uppstår en rad etiska dilemman och konflikter med nuvarande dataskyddsregler.
            Detta diskuteras i detalj i t ex denna avhandling.
            <ref target="i-KDT6yzqhfky4xGujFJudHE">
              [3]
            </ref>
          </p>
          <p xml:id="i-CzHmJZeA6J2anGtVPNEPHF">
            I dagspressen kan man ibland läsa om oron för att AI ska bli
            medveten eller bli ondskefull. Men det som oroar de som forskar
            i ämnet är snarare att AI ska bli intelligentare än oss och att
            det uppstår målkonflikter där de mål AI sätter upp för att lösa
            ett problem inte sammanfaller med de mål människor sätter upp.
          </p>
          <p xml:id="i-ApDsfFnnZYgMQb14NfRxPY">
            Om vi vill ha ett vattenkraftverk vill vi inte döda myrorna i
            myrstacken i dalgången, men vi gör det för att vi inte anser att
            konsekvenserna för dem är skäl nog att avstå från en effektiv
            lösning för att få energi. Likaså kan en AI satt att lösa ett
            problem göra en annan värdering om lösningen är värd konsekvenserna
            än vad en människa hade gjort med samma intelligens eller kunskap.
            Men vad händer när vi inte längre har en chans att nå samma intelligens
            eller kunskap?
          </p>
          <p xml:id="i-B4oE3Va8e3r3Qwpv6n1TLd">
            Hur utvecklar vi den etik och moral och kontroll över AI som
            gör att AI, inte av ondska men av ren effektivitet, väljer en
            utveckling som vi människor inte hade valt, eller som en demokratisk
            majoritet inte hade valt? Hur påverkar AI maktstrukturer i samhället
            och hur undviks maktkoncentration?
          </p>
          <p xml:id="i-PgAJVwcRsG1ekMyxEFwtfy">
            Problemet är inte huvudsakligen terminatorrobotar som förgör
            mänskligheten men att AI genom enkel uppkoppling mot internet
            med överlägsen intelligens och kunskap kan styra/betala människor
            att följa icke önskvärda mål eller en icke önskvärd samhällsutveckling.
            Eller för flertalet icke önskvärd utveckling.
          </p>
          <p xml:id="i-Knwi6nPB6vhRYvZEcgQSLa">
            Samhället behöver därför utveckla sin analysförmåga över hur
            vi vill använda AI och till vad det inte bör användas. Vi behöver
            veta vilka etiska, moraliska begränsningar som bör införas för
            AI samt hur big data ska tillgängliggöras till AI-system och med
            risk för förlorad kontroll över data och deras behandling. Idag
            oroar sig många för hur inflytande kan köpas genom kontroll av
            och kunskap kring vad som sker i sociala medier. I framtiden kan
            avancerad AI göra analyser som är bortom mänsklig förmåga att
            förstå eller kontrollera.
          </p>
          <p xml:id="i-XpmB8pSpMZzSv5yv5aUEft">
            Det är därför av yttersta vikt att Sverige och andra länder påbörjar
            en diskussion kring riskerna och fördelarna med AI och hur utveckling
            bör regleras och kontrolleras.
          </p>
          <p xml:id="i-B8424TPfJe5L3ofgXMWoJj">
            Ansvaret för vad ett AI-system gör bör tydligt regleras så att
            det alltid finns människor att ställa till svars för vad en AI
            gör. Regler som gäller människor och företag bör också gälla AI
            så att AI inte används för insider trading eller andra marknadsmanipulationer
            eller manipulation av demokratin.
          </p>
          <p xml:id="i-WvWLTcgzVyeZKL4FtKKdSX">
            AI-system måste tydligt deklarera att det är en AI som människor
            interagerar med. Vi har sett hur Trump-bots och hur chatt-tjänster
            lurar folk att tro att det är riktiga människor på andra sidan,
            det är en form av falsk marknadsföring.
          </p>
          <p xml:id="i-3Fdr9JttmjqxyPqGfcjUiF">
            AI har en enorm förmåga att samla och bearbeta hemlig eller känslig
            information. Det bör tydligt regleras hur kontroll av sådan information
            ska ske så att det är möjligt att utkräva tydligt ansvar för brott
            mot sekretess-, finans- eller dataskyddslagar.
          </p>
          <p xml:id="i-8sv7cNMqLLmU5WAZrpCY8c">
            Regler för automatisk avstängning av automatiska processer vid
            anomalier bör utvecklas. T ex har automatiska handelsrobotar stört
            marknaden vid flera tillfällen.
          </p>
          <p xml:id="i-aRBQ87tKcMDZdSrCnCPvg">
            AI som är självutvecklande och fullt automatiserad utan mänsklig
            inblandning bör begränsas så att den inte kan sprida sig fritt
            och vi inte därmed förlorar kontrollen över den.
          </p>
          <p xml:id="i-WNNp5CMwdNYnWJQNGq72dL">
            AI är fortfarande i sin tidiga utvecklingsfas och vilka tillämpningar
            och områden som kan bli problematiska och vilka som har stor potential
            att hjälpa oss är ännu svårt att avgöra. Då tekniken fortfarande
            också har karaktär av grundforskning såväl som tillämpad teknik
            vill vi heller inte i detta skede överreglera. Det är dock hög
            tid att diskutera och förutsäga rimliga problem som kan uppstå
            och inleda arbetet med att systematisera vad som kan behöva regleras
            och vilka utvecklingsvägar som kan innebära fara för att mänskligheten
            förlorar herraväldet över sin egen teknik.
          </p>
          <head xml:id="i-XCzFCZfNH5aB64KecXdhjv" type="h2">
            Förslagen
          </head>
          <p xml:id="i-R52N3c6t8hqY6CzsiuLvsV">
            Sverige bör vara pådrivande inom FN och andra sammanhang för
            att förbjuda autonoma dödliga vapensystem.
          </p>
          <p xml:id="i-VFA2ZyfvM6EyoopEvDFM3D">
            Sverige bör vara föregångare på området för effektiv analys och
            reglering av AI. Detta skulle kunna ge oss stora konkurrensfördelar
            genom att vara med att utveckla nya globala standarder på området
            samt skydda oss från förlust av demokratiska fri- och rättigheter.
          </p>
        </div>
        <div type="motSignatures">
          <list>
            <item xml:id="i-LUMxq2at6Zmv19WpSCsLRG">
              Carl Schlyter (MP)
            </item>
          </list>
        </div>
        <div type="motNotes">
          <noteGrp>
            <note xml:id="i-U4Skiewj7Ckp1NWULHRrZm">
              [1] https://futureoflife.org/open-letter-autonomous-weapons/.
            </note>
            <note xml:id="i-WcqY8HR135CMva4agEqUvH">
              [2] http://www.medianet.com.au/releases/141447/.
            </note>
            <note xml:id="i-KDT6yzqhfky4xGujFJudHE">
              [3] http://su.diva-portal.org/smash/get/diva2:1088890/FULLTEXT01.pdf.
            </note>
          </noteGrp>
        </div>
      </div>
    </body>
  </text>
</TEI>
